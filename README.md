用Ollama部署本地大模型或这接入DeepSeek的API后，用户通过前端Web页面向LLM提问。
根据RAG的思想，先将用户的问题用嵌入模型转化成向量，与数据库存放的内容切片的向量计算相似度，将相似内容与历史对话等信息拼接在Prompt中
一并传给LLM，然后获取LLM的回复。
